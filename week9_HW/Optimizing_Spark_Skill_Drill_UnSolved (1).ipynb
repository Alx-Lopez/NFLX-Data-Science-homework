{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optimizing_Spark_Skill_Drill_UnSolved.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcbx0f2q27rD"
      },
      "source": [
        " # Skill Drill: Putting it ALL together\n",
        " ## Overview\n",
        "\n",
        " A VP at your company has written a SQL for a report that shows how much time is being lost due to flight delays by Airport and Carrier.  It is performing below expectations.  Using all of the optimizing skills you have learned in Unit 8, get this query to run as fast as possible.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Hint: Initial query takes between 15-20 seconds.  Final query should be <2 seconds\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGA5-htN6oEN",
        "outputId": "ae63eed9-893f-44f1-d914-b63c2f65b093"
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.1'\n",
        "spark_version = 'spark-3.0.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 14.2 kB/88.7\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 14.2 kB/88.7\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 34.4 kB/88.7\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [685 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,446 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,444 kB]\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [829 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,813 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [719 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,225 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [930 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,888 kB]\n",
            "Fetched 14.3 MB in 4s (3,543 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIUo9MYO6vlj"
      },
      "source": [
        "#import packages\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import StructType,StructField,StringType, DateType,IntegerType\n",
        "import pandas as pd\n",
        "\n",
        "# we are going to use this to time our queries.\n",
        "import time\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej6Sabcd-1At"
      },
      "source": [
        "# Read in data from S3 Bucket\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-netflix/DelayedFlights.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"DelayedFlights.csv\"), sep=\",\", header=True)\n",
        "url_cities='https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-netflix/cities500.txt'\n",
        "spark.sparkContext.addFile(url_cities)\n",
        "df_lookup_geo = spark.read.csv(SparkFiles.get(\"cities500.txt\"), sep=\"\\t\", header=True)\n",
        "\n",
        "# we are going to do a lookup here as well so upload the airportCodes.csv file from you Resources directory \n",
        "df_lookup_city_name=spark.read.csv('/content/airportCodes.csv', sep=',', header=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DFhjm5Z_O5Z"
      },
      "source": [
        "#Create temporary views for each of our dataframes\n",
        "# We are going to filter the data to US only as we create the Temp Views.\n",
        "\n",
        "df.createOrReplaceTempView('delayed')\n",
        "df_lookup_city_name.createOrReplaceTempView('lookup_city')\n",
        "df_lookup_geo.createOrReplaceTempView('lookup_geo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhgb2iFihRbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74325f70-bb8e-4421-afca-b28c01018d0e"
      },
      "source": [
        "# Here is the  initial query presented to you for optimization\n",
        "# Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "with allColumns\n",
        "(select \n",
        "a.Year,\n",
        "a.Month,\n",
        "a.DayofMonth,\n",
        "a.DayOfWeek,\n",
        "a.DepTime,\n",
        "a.CRSDepTime,\n",
        "a.ArrTime,\n",
        "a.CRSArrTime,\n",
        "a.UniqueCarrier,\n",
        "a.FlightNum,\n",
        "a.TailNum,\n",
        "a.ActualElapsedTime,\n",
        "a.CRSElapsedTime,\n",
        "a.AirTime,\n",
        "a.ArrDelay,\n",
        "a.DepDelay,\n",
        "a.Origin,\n",
        "b.City as Origin_City,\n",
        "geo.latitude as Origin_latitude,\n",
        "geo.longitude as Origin_longitude,\n",
        "a.Dest,\n",
        "c.City as Dest_City,\n",
        "geo_dest.latitude as Dest_latitude,\n",
        "geo_dest.longitude as Dest_longitude,\n",
        "a.Distance,\n",
        "a.TaxiIn,\n",
        "a.TaxiOut,\n",
        "a.Cancelled,\n",
        "a.CancellationCode,\n",
        "a.Diverted,\n",
        "a.CarrierDelay,\n",
        "a.WeatherDelay,\n",
        "a.NASDelay,\n",
        "a.SecurityDelay,\n",
        "a.LateAircraftDelay from  delayed a \n",
        "  inner join lookup_city b\n",
        "    on a.Origin=b.airportCode\n",
        "  inner join lookup_city c\n",
        "    on a.Dest=c.airportCode\n",
        "  inner join lookup_geo geo\n",
        "on split(b.City,',')[0]=geo.name\n",
        "     and trim(split(b.City,',')[1])=geo.admin1_code\n",
        "  inner join lookup_geo geo_dest\n",
        "    on c.City=concat(geo_dest.name,', ',geo_dest.admin1_code)\n",
        ")\n",
        "select Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude, max(DepDelay) as delayed, avg(CarrierDelay) avgCarrierDelay \n",
        "from allColumns \n",
        "group by Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude\n",
        "\"\"\").show()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+---------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|Origin|UniqueCarrier|    Origin_City|Origin_latitude|Origin_Longitude|Dest_latitude|Dest_longitude|delayed|   avgCarrierDelay|\n",
            "+------+-------------+---------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|   ATL|           EV|    Atlanta, GA|         33.749|       -84.38798|     31.31129|     -92.44514|   99.0| 28.81025641025641|\n",
            "|   ABQ|           DL|Albuquerque, NM|       35.08449|      -106.65114|       33.749|     -84.38798|   99.0|40.401869158878505|\n",
            "|   ATW|           EV|   Appleton, WI|       44.26193|       -88.41538|       33.749|     -84.38798|   99.0|30.546666666666667|\n",
            "|   BWI|           WN|  Baltimore, MD|       39.29038|       -76.61219|     30.26715|     -97.74306|   95.0|12.741935483870968|\n",
            "|   CAK|           EV|      Akron, OH|       41.08144|       -81.51901|       33.749|     -84.38798|   99.0|28.156941649899398|\n",
            "|   ATL|           OH|    Atlanta, GA|         33.749|       -84.38798|     30.26715|     -97.74306|   97.0| 40.42245989304813|\n",
            "|   CAK|           FL|      Akron, OH|       41.08144|       -81.51901|     42.35843|     -71.05977|   99.0|  2.63302752293578|\n",
            "|   AEX|           EV| Alexandria, LA|       31.31129|       -92.44514|       33.749|     -84.38798|   96.0|27.155778894472363|\n",
            "|   BMI|           FL|Bloomington, IL|        40.4842|       -88.99369|       33.749|     -84.38798|   98.0| 8.437158469945356|\n",
            "|   BOS|           OH|     Boston, MA|       42.35843|       -71.05977|     44.80118|     -68.77781|   95.0|18.462311557788944|\n",
            "|   ATL|           EV|    Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|   99.0| 30.99437148217636|\n",
            "|   CAK|           DL|      Akron, OH|       41.08144|       -81.51901|       33.749|     -84.38798|    9.0| 27.91304347826087|\n",
            "|   ATL|           FL|    Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|   99.0| 12.44890510948905|\n",
            "|   BOS|           FL|     Boston, MA|       42.35843|       -71.05977|     41.08144|     -81.51901|   99.0|1.0092592592592593|\n",
            "|   BHM|           EV| Birmingham, AL|       33.52066|       -86.80249|       33.749|     -84.38798|   96.0| 17.04794520547945|\n",
            "|   ATL|           DL|    Atlanta, GA|         33.749|       -84.38798|     35.08449|    -106.65114|   98.0|20.948275862068964|\n",
            "|   BRW|           AS|     Barrow, AK|       71.29058|      -156.78872|     61.21806|    -149.90028|   97.0| 4.483516483516484|\n",
            "|   ATL|           OO|    Atlanta, GA|         33.749|       -84.38798|     30.26715|     -97.74306|    6.0|              19.0|\n",
            "|   ASE|           OO|      Aspen, CO|        39.1911|      -106.81754|       33.749|     -84.38798|   82.0|               6.0|\n",
            "|   BWI|           EV|  Baltimore, MD|       39.29038|       -76.61219|       33.749|     -84.38798|   93.0|              15.5|\n",
            "+------+-------------+---------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 20.14763593673706 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_797bPxUaFOY"
      },
      "source": [
        "#partition the largest table\n",
        "df.write.parquet('parquet_delayed',mode='overwrite')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R7wBwdVbk-f"
      },
      "source": [
        "# read the new parquet formatted data\n",
        "p_df=spark.read.parquet('parquet_delayed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oWokIp2b0Ba"
      },
      "source": [
        "# create a view (same name as before so we don't have change our SQL)\n",
        "p_df.createOrReplaceTempView('delayed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc4uyu-sb8zY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1869e7e6-6233-491d-c525-146fd7a773cd"
      },
      "source": [
        "# run 2 after storing the data more appropriately and partitioning\n",
        "\n",
        "# Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "with allColumns\n",
        "(select \n",
        "a.Year,\n",
        "a.Month,\n",
        "a.DayofMonth,\n",
        "a.DayOfWeek,\n",
        "a.DepTime,\n",
        "a.CRSDepTime,\n",
        "a.ArrTime,\n",
        "a.CRSArrTime,\n",
        "a.UniqueCarrier,\n",
        "a.FlightNum,\n",
        "a.TailNum,\n",
        "a.ActualElapsedTime,\n",
        "a.CRSElapsedTime,\n",
        "a.AirTime,\n",
        "a.ArrDelay,\n",
        "a.DepDelay,\n",
        "a.Origin,\n",
        "b.City as Origin_City,\n",
        "geo.latitude as Origin_latitude,\n",
        "geo.longitude as Origin_longitude,\n",
        "a.Dest,\n",
        "c.City as Dest_City,\n",
        "geo_dest.latitude as Dest_latitude,\n",
        "geo_dest.longitude as Dest_longitude,\n",
        "a.Distance,\n",
        "a.TaxiIn,\n",
        "a.TaxiOut,\n",
        "a.Cancelled,\n",
        "a.CancellationCode,\n",
        "a.Diverted,\n",
        "a.CarrierDelay,\n",
        "a.WeatherDelay,\n",
        "a.NASDelay,\n",
        "a.SecurityDelay,\n",
        "a.LateAircraftDelay from  delayed a \n",
        "  inner join lookup_city b\n",
        "    on a.Origin=b.airportCode\n",
        "  inner join lookup_city c\n",
        "    on a.Dest=c.airportCode\n",
        "  inner join lookup_geo geo\n",
        "on split(b.City,',')[0]=geo.name\n",
        "     and trim(split(b.City,',')[1])=geo.admin1_code\n",
        "  inner join lookup_geo geo_dest\n",
        "    on c.City=concat(geo_dest.name,', ',geo_dest.admin1_code)\n",
        ")\n",
        "select Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude, max(DepDelay) as delayed, avg(CarrierDelay) avgCarrierDelay \n",
        "from allColumns \n",
        "group by Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude\n",
        "\"\"\").show()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+---------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|Origin|UniqueCarrier|    Origin_City|Origin_latitude|Origin_Longitude|Dest_latitude|Dest_longitude|delayed|   avgCarrierDelay|\n",
            "+------+-------------+---------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|   ATL|           EV|    Atlanta, GA|         33.749|       -84.38798|     31.31129|     -92.44514|   99.0| 28.81025641025641|\n",
            "|   ABQ|           DL|Albuquerque, NM|       35.08449|      -106.65114|       33.749|     -84.38798|   99.0|40.401869158878505|\n",
            "|   ATW|           EV|   Appleton, WI|       44.26193|       -88.41538|       33.749|     -84.38798|   99.0|30.546666666666667|\n",
            "|   BWI|           WN|  Baltimore, MD|       39.29038|       -76.61219|     30.26715|     -97.74306|   95.0|12.741935483870968|\n",
            "|   CAK|           EV|      Akron, OH|       41.08144|       -81.51901|       33.749|     -84.38798|   99.0|28.156941649899398|\n",
            "|   ATL|           OH|    Atlanta, GA|         33.749|       -84.38798|     30.26715|     -97.74306|   97.0| 40.42245989304813|\n",
            "|   CAK|           FL|      Akron, OH|       41.08144|       -81.51901|     42.35843|     -71.05977|   99.0|  2.63302752293578|\n",
            "|   AEX|           EV| Alexandria, LA|       31.31129|       -92.44514|       33.749|     -84.38798|   96.0|27.155778894472363|\n",
            "|   BMI|           FL|Bloomington, IL|        40.4842|       -88.99369|       33.749|     -84.38798|   98.0| 8.437158469945356|\n",
            "|   BOS|           OH|     Boston, MA|       42.35843|       -71.05977|     44.80118|     -68.77781|   95.0|18.462311557788944|\n",
            "|   ATL|           EV|    Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|   99.0| 30.99437148217636|\n",
            "|   CAK|           DL|      Akron, OH|       41.08144|       -81.51901|       33.749|     -84.38798|    9.0| 27.91304347826087|\n",
            "|   ATL|           FL|    Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|   99.0| 12.44890510948905|\n",
            "|   BOS|           FL|     Boston, MA|       42.35843|       -71.05977|     41.08144|     -81.51901|   99.0|1.0092592592592593|\n",
            "|   BHM|           EV| Birmingham, AL|       33.52066|       -86.80249|       33.749|     -84.38798|   96.0| 17.04794520547945|\n",
            "|   ATL|           DL|    Atlanta, GA|         33.749|       -84.38798|     35.08449|    -106.65114|   98.0|20.948275862068964|\n",
            "|   BRW|           AS|     Barrow, AK|       71.29058|      -156.78872|     61.21806|    -149.90028|   97.0| 4.483516483516484|\n",
            "|   ATL|           OO|    Atlanta, GA|         33.749|       -84.38798|     30.26715|     -97.74306|    6.0|              19.0|\n",
            "|   ASE|           OO|      Aspen, CO|        39.1911|      -106.81754|       33.749|     -84.38798|   82.0|               6.0|\n",
            "|   BWI|           EV|  Baltimore, MD|       39.29038|       -76.61219|       33.749|     -84.38798|   93.0|              15.5|\n",
            "+------+-------------+---------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 7.055324554443359 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f3iZbtlcMZ6"
      },
      "source": [
        "# Recall that the default shuffle partitions is 200.  We want to bring that down to a reasonable size for both our data and our Spark cluster\n",
        "# 4 is reasonable for a free Colab \n",
        "spark.conf.set(\"spark.sql.shuffle.partitions\",4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvYdTGRCcQjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9748619-34f0-40b7-89ec-a6911b65acc8"
      },
      "source": [
        "# Run 3 after setting the shuffle partitions to a more appropriate number\n",
        "# Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "with allColumns\n",
        "(select \n",
        "a.Year,\n",
        "a.Month,\n",
        "a.DayofMonth,\n",
        "a.DayOfWeek,\n",
        "a.DepTime,\n",
        "a.CRSDepTime,\n",
        "a.ArrTime,\n",
        "a.CRSArrTime,\n",
        "a.UniqueCarrier,\n",
        "a.FlightNum,\n",
        "a.TailNum,\n",
        "a.ActualElapsedTime,\n",
        "a.CRSElapsedTime,\n",
        "a.AirTime,\n",
        "a.ArrDelay,\n",
        "a.DepDelay,\n",
        "a.Origin,\n",
        "b.City as Origin_City,\n",
        "geo.latitude as Origin_latitude,\n",
        "geo.longitude as Origin_longitude,\n",
        "a.Dest,\n",
        "c.City as Dest_City,\n",
        "geo_dest.latitude as Dest_latitude,\n",
        "geo_dest.longitude as Dest_longitude,\n",
        "a.Distance,\n",
        "a.TaxiIn,\n",
        "a.TaxiOut,\n",
        "a.Cancelled,\n",
        "a.CancellationCode,\n",
        "a.Diverted,\n",
        "a.CarrierDelay,\n",
        "a.WeatherDelay,\n",
        "a.NASDelay,\n",
        "a.SecurityDelay,\n",
        "a.LateAircraftDelay from  delayed a \n",
        "  inner join lookup_city b\n",
        "    on a.Origin=b.airportCode\n",
        "  inner join lookup_city c\n",
        "    on a.Dest=c.airportCode\n",
        "  inner join lookup_geo geo\n",
        "on split(b.City,',')[0]=geo.name\n",
        "     and trim(split(b.City,',')[1])=geo.admin1_code\n",
        "  inner join lookup_geo geo_dest\n",
        "    on c.City=concat(geo_dest.name,', ',geo_dest.admin1_code)\n",
        ")\n",
        "select Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude, max(DepDelay) as delayed, avg(CarrierDelay) avgCarrierDelay \n",
        "from allColumns \n",
        "group by Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude\n",
        "\"\"\").show()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|Origin|UniqueCarrier|  Origin_City|Origin_latitude|Origin_Longitude|Dest_latitude|Dest_longitude|delayed|   avgCarrierDelay|\n",
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|   ABE|           OO|Allentown, PA|       40.60843|       -75.49018|     33.52066|     -86.80249|   11.0|              null|\n",
            "|   ALB|           OH|   Albany, NY|       42.65258|       -73.75623|     42.35843|     -71.05977|   55.0|               0.0|\n",
            "|   ALB|           WN|   Albany, NY|       42.65258|       -73.75623|     39.29038|     -76.61219|   99.0| 8.203647416413373|\n",
            "|   ASE|           OO|    Aspen, CO|        39.1911|      -106.81754|       33.749|     -84.38798|   82.0|               6.0|\n",
            "|   ATL|           9E|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   94.0|15.083333333333334|\n",
            "|   ATL|           9E|  Atlanta, GA|         33.749|       -84.38798|     39.29038|     -76.61219|    6.0|              null|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     30.26715|     -97.74306|   99.0| 20.12719298245614|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   98.0|            19.856|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|    7.0| 17.11111111111111|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     61.21806|    -149.90028|    9.0|             25.75|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     39.29038|     -76.61219|   82.0|              17.6|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     39.36415|     -74.42306|    9.0|  46.1578947368421|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|   99.0| 30.99437148217636|\n",
            "|   ATL|           OH|  Atlanta, GA|         33.749|       -84.38798|     30.44332|     -91.18747|   82.0| 48.13333333333333|\n",
            "|   ATL|           OH|  Atlanta, GA|         33.749|       -84.38798|     40.60843|     -75.49018|    8.0|              16.5|\n",
            "|   ATL|           OO|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   31.0|               0.0|\n",
            "|   ATL|           OO|  Atlanta, GA|         33.749|       -84.38798|      39.1911|    -106.81754|   81.0|13.571428571428571|\n",
            "|   ATW|           OH| Appleton, WI|       44.26193|       -88.41538|       33.749|     -84.38798|   70.0|             46.25|\n",
            "|   AUS|           DL|   Austin, TX|       30.26715|       -97.74306|       33.749|     -84.38798|   96.0| 22.71904761904762|\n",
            "|   AUS|           OH|   Austin, TX|       30.26715|       -97.74306|       33.749|     -84.38798|   90.0|             43.64|\n",
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 5.515564441680908 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPR_2uq0vdyt",
        "outputId": "d847f00f-15bf-4238-9214-0a3cf9fcdf3f"
      },
      "source": [
        "# cache your largest temporary view\n",
        "# Note: when we use SparkSQL to cache a table, the table is immediately cached (no lazy evaluation), when using Pyspark it will not be cached until an action is ran.\n",
        "spark.sql(\"cache table delayed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eodqtIHByC2J",
        "outputId": "492873bf-f86d-4a26-c185-becce6bd28ba"
      },
      "source": [
        "# check that your table is cached \n",
        "spark.catalog.isCached(\"delayed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP7129kUda1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7f93857-bed9-4180-d1cb-d2ec6cf6ffbd"
      },
      "source": [
        "# Run 4 - after caching driver table\n",
        "# Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "with allColumns\n",
        "(select \n",
        "a.Year,\n",
        "a.Month,\n",
        "a.DayofMonth,\n",
        "a.DayOfWeek,\n",
        "a.DepTime,\n",
        "a.CRSDepTime,\n",
        "a.ArrTime,\n",
        "a.CRSArrTime,\n",
        "a.UniqueCarrier,\n",
        "a.FlightNum,\n",
        "a.TailNum,\n",
        "a.ActualElapsedTime,\n",
        "a.CRSElapsedTime,\n",
        "a.AirTime,\n",
        "a.ArrDelay,\n",
        "a.DepDelay,\n",
        "a.Origin,\n",
        "b.City as Origin_City,\n",
        "geo.latitude as Origin_latitude,\n",
        "geo.longitude as Origin_longitude,\n",
        "a.Dest,\n",
        "c.City as Dest_City,\n",
        "geo_dest.latitude as Dest_latitude,\n",
        "geo_dest.longitude as Dest_longitude,\n",
        "a.Distance,\n",
        "a.TaxiIn,\n",
        "a.TaxiOut,\n",
        "a.Cancelled,\n",
        "a.CancellationCode,\n",
        "a.Diverted,\n",
        "a.CarrierDelay,\n",
        "a.WeatherDelay,\n",
        "a.NASDelay,\n",
        "a.SecurityDelay,\n",
        "a.LateAircraftDelay from  delayed a \n",
        "  inner join lookup_city b\n",
        "    on a.Origin=b.airportCode\n",
        "  inner join lookup_city c\n",
        "    on a.Dest=c.airportCode\n",
        "  inner join lookup_geo geo\n",
        "on split(b.City,',')[0]=geo.name\n",
        "     and trim(split(b.City,',')[1])=geo.admin1_code\n",
        "  inner join lookup_geo geo_dest\n",
        "    on c.City=concat(geo_dest.name,', ',geo_dest.admin1_code)\n",
        ")\n",
        "select Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude, max(DepDelay) as delayed, avg(CarrierDelay) avgCarrierDelay \n",
        "from allColumns \n",
        "group by Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude\n",
        "\"\"\").show()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|Origin|UniqueCarrier|  Origin_City|Origin_latitude|Origin_Longitude|Dest_latitude|Dest_longitude|delayed|   avgCarrierDelay|\n",
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|   ABE|           OO|Allentown, PA|       40.60843|       -75.49018|     33.52066|     -86.80249|   11.0|              null|\n",
            "|   ALB|           OH|   Albany, NY|       42.65258|       -73.75623|     42.35843|     -71.05977|   55.0|               0.0|\n",
            "|   ALB|           WN|   Albany, NY|       42.65258|       -73.75623|     39.29038|     -76.61219|   99.0| 8.203647416413373|\n",
            "|   ASE|           OO|    Aspen, CO|        39.1911|      -106.81754|       33.749|     -84.38798|   82.0|               6.0|\n",
            "|   ATL|           9E|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   94.0|15.083333333333334|\n",
            "|   ATL|           9E|  Atlanta, GA|         33.749|       -84.38798|     39.29038|     -76.61219|    6.0|              null|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     30.26715|     -97.74306|   99.0| 20.12719298245614|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   98.0|            19.856|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|    7.0| 17.11111111111111|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     61.21806|    -149.90028|    9.0|             25.75|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     39.29038|     -76.61219|   82.0|              17.6|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     39.36415|     -74.42306|    9.0|  46.1578947368421|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|   99.0| 30.99437148217636|\n",
            "|   ATL|           OH|  Atlanta, GA|         33.749|       -84.38798|     30.44332|     -91.18747|   82.0| 48.13333333333333|\n",
            "|   ATL|           OH|  Atlanta, GA|         33.749|       -84.38798|     40.60843|     -75.49018|    8.0|              16.5|\n",
            "|   ATL|           OO|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   31.0|               0.0|\n",
            "|   ATL|           OO|  Atlanta, GA|         33.749|       -84.38798|      39.1911|    -106.81754|   81.0|13.571428571428571|\n",
            "|   ATW|           OH| Appleton, WI|       44.26193|       -88.41538|       33.749|     -84.38798|   70.0|             46.25|\n",
            "|   AUS|           DL|   Austin, TX|       30.26715|       -97.74306|       33.749|     -84.38798|   96.0| 22.71904761904762|\n",
            "|   AUS|           OH|   Austin, TX|       30.26715|       -97.74306|       33.749|     -84.38798|   90.0|             43.64|\n",
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 5.852593660354614 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfvIwCCChuvc",
        "outputId": "7060d74c-743a-419a-94b9-967bee084adf"
      },
      "source": [
        "# you can even cache a large lookup table.\n",
        "spark.sql(\"cache table delayed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31NhqcGgh7HG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfbad51c-2d17-47fa-c44f-e9de0bc478e5"
      },
      "source": [
        "# Run 5 - caching one of the lookups\n",
        "#Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "with allColumns\n",
        "(select \n",
        "a.Year,\n",
        "a.Month,\n",
        "a.DayofMonth,\n",
        "a.DayOfWeek,\n",
        "a.DepTime,\n",
        "a.CRSDepTime,\n",
        "a.ArrTime,\n",
        "a.CRSArrTime,\n",
        "a.UniqueCarrier,\n",
        "a.FlightNum,\n",
        "a.TailNum,\n",
        "a.ActualElapsedTime,\n",
        "a.CRSElapsedTime,\n",
        "a.AirTime,\n",
        "a.ArrDelay,\n",
        "a.DepDelay,\n",
        "a.Origin,\n",
        "b.City as Origin_City,\n",
        "geo.latitude as Origin_latitude,\n",
        "geo.longitude as Origin_longitude,\n",
        "a.Dest,\n",
        "c.City as Dest_City,\n",
        "geo_dest.latitude as Dest_latitude,\n",
        "geo_dest.longitude as Dest_longitude,\n",
        "a.Distance,\n",
        "a.TaxiIn,\n",
        "a.TaxiOut,\n",
        "a.Cancelled,\n",
        "a.CancellationCode,\n",
        "a.Diverted,\n",
        "a.CarrierDelay,\n",
        "a.WeatherDelay,\n",
        "a.NASDelay,\n",
        "a.SecurityDelay,\n",
        "a.LateAircraftDelay from  delayed a \n",
        "  inner join lookup_city b\n",
        "    on a.Origin=b.airportCode\n",
        "  inner join lookup_city c\n",
        "    on a.Dest=c.airportCode\n",
        "  inner join lookup_geo geo\n",
        "on split(b.City,',')[0]=geo.name\n",
        "     and trim(split(b.City,',')[1])=geo.admin1_code\n",
        "  inner join lookup_geo geo_dest\n",
        "    on c.City=concat(geo_dest.name,', ',geo_dest.admin1_code)\n",
        ")\n",
        "select Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude, max(DepDelay) as delayed, avg(CarrierDelay) avgCarrierDelay \n",
        "from allColumns \n",
        "group by Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude\n",
        "\"\"\").show()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|Origin|UniqueCarrier|  Origin_City|Origin_latitude|Origin_Longitude|Dest_latitude|Dest_longitude|delayed|   avgCarrierDelay|\n",
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|   ABE|           OO|Allentown, PA|       40.60843|       -75.49018|     33.52066|     -86.80249|   11.0|              null|\n",
            "|   ALB|           OH|   Albany, NY|       42.65258|       -73.75623|     42.35843|     -71.05977|   55.0|               0.0|\n",
            "|   ALB|           WN|   Albany, NY|       42.65258|       -73.75623|     39.29038|     -76.61219|   99.0| 8.203647416413373|\n",
            "|   ASE|           OO|    Aspen, CO|        39.1911|      -106.81754|       33.749|     -84.38798|   82.0|               6.0|\n",
            "|   ATL|           9E|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   94.0|15.083333333333334|\n",
            "|   ATL|           9E|  Atlanta, GA|         33.749|       -84.38798|     39.29038|     -76.61219|    6.0|              null|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     30.26715|     -97.74306|   99.0| 20.12719298245614|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   98.0|            19.856|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|    7.0| 17.11111111111111|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     61.21806|    -149.90028|    9.0|             25.75|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     39.29038|     -76.61219|   82.0|              17.6|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     39.36415|     -74.42306|    9.0|  46.1578947368421|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|   99.0| 30.99437148217636|\n",
            "|   ATL|           OH|  Atlanta, GA|         33.749|       -84.38798|     30.44332|     -91.18747|   82.0| 48.13333333333333|\n",
            "|   ATL|           OH|  Atlanta, GA|         33.749|       -84.38798|     40.60843|     -75.49018|    8.0|              16.5|\n",
            "|   ATL|           OO|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   31.0|               0.0|\n",
            "|   ATL|           OO|  Atlanta, GA|         33.749|       -84.38798|      39.1911|    -106.81754|   81.0|13.571428571428571|\n",
            "|   ATW|           OH| Appleton, WI|       44.26193|       -88.41538|       33.749|     -84.38798|   70.0|             46.25|\n",
            "|   AUS|           DL|   Austin, TX|       30.26715|       -97.74306|       33.749|     -84.38798|   96.0| 22.71904761904762|\n",
            "|   AUS|           OH|   Austin, TX|       30.26715|       -97.74306|       33.749|     -84.38798|   90.0|             43.64|\n",
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 4.459480047225952 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDO8GpNZe7gc",
        "outputId": "c67f3fe1-bfea-425b-d6b3-7a41adf9fcbd"
      },
      "source": [
        "# run 6 - remove unnecesary columns from the SQL\n",
        "# Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "spark.sql('''with allColumns\n",
        "(select \n",
        "a.UniqueCarrier,\n",
        "a.ArrDelay,\n",
        "a.DepDelay,\n",
        "a.Origin,\n",
        "b.City as Origin_City,\n",
        "geo.latitude as Origin_latitude,\n",
        "geo.longitude as Origin_longitude,\n",
        "a.Dest,\n",
        "c.City as Dest_City,\n",
        "geo_dest.latitude as Dest_latitude,\n",
        "geo_dest.longitude as Dest_longitude,\n",
        "a.Distance,\n",
        "a.CarrierDelay,\n",
        "a.WeatherDelay,\n",
        "a.NASDelay,\n",
        "a.SecurityDelay,\n",
        "a.LateAircraftDelay from  delayed a \n",
        "  inner join lookup_city b\n",
        "    on a.Origin=b.airportCode\n",
        "  inner join lookup_city c\n",
        "    on a.Dest=c.airportCode\n",
        "  inner join lookup_geo geo\n",
        "on split(b.City,',')[0]=geo.name\n",
        "     and trim(split(b.City,',')[1])=geo.admin1_code\n",
        "  inner join lookup_geo geo_dest\n",
        "    on c.City=concat(geo_dest.name,', ',geo_dest.admin1_code)\n",
        ")\n",
        "select Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude, max(DepDelay) as delayed, avg(CarrierDelay) avgCarrierDelay \n",
        "from allColumns \n",
        "group by Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude ''').show()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|Origin|UniqueCarrier|  Origin_City|Origin_latitude|Origin_Longitude|Dest_latitude|Dest_longitude|delayed|   avgCarrierDelay|\n",
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|   ABE|           OO|Allentown, PA|       40.60843|       -75.49018|     33.52066|     -86.80249|   11.0|              null|\n",
            "|   ALB|           OH|   Albany, NY|       42.65258|       -73.75623|     42.35843|     -71.05977|   55.0|               0.0|\n",
            "|   ALB|           WN|   Albany, NY|       42.65258|       -73.75623|     39.29038|     -76.61219|   99.0| 8.203647416413373|\n",
            "|   ASE|           OO|    Aspen, CO|        39.1911|      -106.81754|       33.749|     -84.38798|   82.0|               6.0|\n",
            "|   ATL|           9E|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   94.0|15.083333333333334|\n",
            "|   ATL|           9E|  Atlanta, GA|         33.749|       -84.38798|     39.29038|     -76.61219|    6.0|              null|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     30.26715|     -97.74306|   99.0| 20.12719298245614|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   98.0|            19.856|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|    7.0| 17.11111111111111|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     61.21806|    -149.90028|    9.0|             25.75|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     39.29038|     -76.61219|   82.0|              17.6|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     39.36415|     -74.42306|    9.0|  46.1578947368421|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|   99.0| 30.99437148217636|\n",
            "|   ATL|           OH|  Atlanta, GA|         33.749|       -84.38798|     30.44332|     -91.18747|   82.0| 48.13333333333333|\n",
            "|   ATL|           OH|  Atlanta, GA|         33.749|       -84.38798|     40.60843|     -75.49018|    8.0|              16.5|\n",
            "|   ATL|           OO|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   31.0|               0.0|\n",
            "|   ATL|           OO|  Atlanta, GA|         33.749|       -84.38798|      39.1911|    -106.81754|   81.0|13.571428571428571|\n",
            "|   ATW|           OH| Appleton, WI|       44.26193|       -88.41538|       33.749|     -84.38798|   70.0|             46.25|\n",
            "|   AUS|           DL|   Austin, TX|       30.26715|       -97.74306|       33.749|     -84.38798|   96.0| 22.71904761904762|\n",
            "|   AUS|           OH|   Austin, TX|       30.26715|       -97.74306|       33.749|     -84.38798|   90.0|             43.64|\n",
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 4.29500412940979 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bl4WnpzdfZb4",
        "outputId": "f1c360d4-58b8-4973-fd55-b003e07f9fb0"
      },
      "source": [
        "# run 7 - filter the lookup tables in the SQL\n",
        "# Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "< re-write your sql applying a filter to each lookup table>\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:An unexpected error occurred while tokenizing input\n",
            "The following traceback may be corrupted or invalid\n",
            "The error message is: ('EOF in multi-line string', (1, 110))\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-9b992fb70143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mselect\u001b[0m \u001b[0mOrigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUniqueCarrier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrigin_City\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrigin_latitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrigin_Longitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDest_latitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDest_longitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDepDelay\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCarrierDelay\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mavgCarrierDelay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallColumns\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCarrierDelay\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m group by Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude ''').show()\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.1-bin-hadoop2.7/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \"\"\"\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.1-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: \nAggregate/Window/Generate expressions are not valid in where clause of the query.\nExpression in where clause: [(avg(CAST(allColumns.`CarrierDelay` AS DOUBLE)) < CAST(20 AS DOUBLE))]\nInvalid expressions: [avg(CAST(allColumns.`CarrierDelay` AS DOUBLE))];;\nAggregate [Origin#330, UniqueCarrier#322, Origin_City#7963, Origin_latitude#7964, Origin_Longitude#7965, Dest_latitude#7967, Dest_longitude#7968], [Origin#330, UniqueCarrier#322, Origin_City#7963, Origin_latitude#7964, Origin_Longitude#7965, Dest_latitude#7967, Dest_longitude#7968, max(DepDelay#329) AS delayed#7961, avg(cast(CarrierDelay#338 as double)) AS avgCarrierDelay#7962]\n+- Filter (avg(cast(CarrierDelay#338 as double)) < cast(20 as double))\n   +- SubqueryAlias allColumns\n      +- Project [UniqueCarrier#322, ArrDelay#328, DepDelay#329, Origin#330, City#146 AS Origin_City#7963, latitude#96 AS Origin_latitude#7964, longitude#97 AS Origin_longitude#7965, Dest#331, City#7969 AS Dest_City#7966, latitude#7976 AS Dest_latitude#7967, longitude#7977 AS Dest_longitude#7968, Distance#332, CarrierDelay#338, WeatherDelay#339, NASDelay#340, SecurityDelay#341, LateAircraftDelay#342]\n         +- Join Inner, (City#7969 = concat(name#7973, , , admin1_code#7982))\n            :- Join Inner, ((split(City#146, ,, -1)[0] = name#93) AND (trim(split(City#146, ,, -1)[1], None) = admin1_code#102))\n            :  :- Join Inner, (Dest#331 = airportCode#7971)\n            :  :  :- Join Inner, (Origin#330 = airportCode#148)\n            :  :  :  :- SubqueryAlias a\n            :  :  :  :  +- SubqueryAlias delayed\n            :  :  :  :     +- Relation[_c0#313,Year#314,Month#315,DayofMonth#316,DayOfWeek#317,DepTime#318,CRSDepTime#319,ArrTime#320,CRSArrTime#321,UniqueCarrier#322,FlightNum#323,TailNum#324,ActualElapsedTime#325,CRSElapsedTime#326,AirTime#327,ArrDelay#328,DepDelay#329,Origin#330,Dest#331,Distance#332,TaxiIn#333,TaxiOut#334,Cancelled#335,CancellationCode#336,... 6 more fields] parquet\n            :  :  :  +- SubqueryAlias b\n            :  :  :     +- SubqueryAlias lookup_city\n            :  :  :        +- Relation[City#146,country#147,airportCode#148] csv\n            :  :  +- SubqueryAlias c\n            :  :     +- SubqueryAlias lookup_city\n            :  :        +- Relation[City#7969,country#7970,airportCode#7971] csv\n            :  +- SubqueryAlias geo\n            :     +- SubqueryAlias lookup_geo\n            :        +- Relation[geonameid#92,name#93,asciiname#94,alternatenames#95,latitude#96,longitude#97,feature_class#98,feature_code#99,country_code#100,cc2#101,admin1_code#102,admin2_code#103,admin3_code#104,admin4_code#105,population#106,elevation#107,dem#108,timezone#109,modification_date#110] csv\n            +- SubqueryAlias geo_dest\n               +- SubqueryAlias lookup_geo\n                  +- Relation[geonameid#7972,name#7973,asciiname#7974,alternatenames#7975,latitude#7976,longitude#7977,feature_class#7978,feature_code#7979,country_code#7980,cc2#7981,admin1_code#7982,admin2_code#7983,admin3_code#7984,admin4_code#7985,population#7986,elevation#7987,dem#7988,timezone#7989,modification_date#7990] csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy6F4EZ4gfSP"
      },
      "source": [
        "#recreate the dataframes selecting only the columns you need, filtering the data before creating the view, then caching the views.\n",
        "# columns needed are 'UniqueCarrier','DepDelay','Origin','CarrierDelay','Dest' from the main table\n",
        "<df.select here>\n",
        "# filter the df_lookup_city data prior to creating the view to only contain USA data\n",
        "\n",
        "# filter the df_lookup_geo data prior to creating the view to only contain US data and select only the columns you need to perform the lookup\n",
        "# fields from geo ('name','latitude','longitude','admin1_code')\n",
        "\n",
        "df_lookup_city_name.createOrReplaceTempView('lookup_city')\n",
        "df_lookup_geo.createOrReplaceTempView('lookup_geo')\n",
        "df.createOrReplaceTempView('delayed')\n",
        "spark.sql(\"cache table delayed\")\n",
        "spark.sql(\"cache table lookup_geo\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmk2rn5Zg-tC"
      },
      "source": [
        "# run 8 - filtered lookup dataframes\n",
        "# Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "<final query should return the same data as the first query, but much faster>\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P82CRVDxk7s"
      },
      "source": [
        "# Remember to uncache the table as soon as you are done.\n",
        "spark.sql(\"uncache table delayed\")\n",
        "spark.sql(\"uncache table lookup_geo\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHEPdkk_x0Ep"
      },
      "source": [
        "#Verify that the table is no longer cached\n",
        "if spark.catalog.isCached(\"delayed\") or spark.catalog.isCached(\"lookup_geo\"):\n",
        "  print(\"a table is till cached\")\n",
        "else:\n",
        "  print(\"all clear\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}